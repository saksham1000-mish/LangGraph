{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5e1e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60906b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb24867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogState(TypedDict):\n",
    "    title: str\n",
    "    outline: str\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be46cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state: BlogState) -> BlogState:\n",
    "    title = state['title']\n",
    "    prompt = f'Generate a detailed outline for a blog on the topic: {title}'\n",
    "    outline = model.invoke(prompt)\n",
    "    state['outline'] = outline\n",
    "    return state\n",
    "\n",
    "def create_blog(state: BlogState) -> BlogState:\n",
    "    title = state['title']\n",
    "    outline = state['outline']\n",
    "    prompt = f'Write a detailed blog on the title - {title} using the follwing outline \\n {outline}'\n",
    "\n",
    "    content = model.invoke(prompt).content\n",
    "\n",
    "    state['content'] = content\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbeb6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(BlogState)\n",
    "\n",
    "graph.add_node('create_outline', create_outline)\n",
    "graph.add_node('create_blog', create_blog)\n",
    "\n",
    "graph.add_edge(START, 'create_outline')\n",
    "graph.add_edge('create_outline', 'create_blog')\n",
    "graph.add_edge('create_blog', END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ed30be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'LangGraph vs LangChain', 'outline': AIMessage(content='## Blog Post Outline: LangGraph vs. LangChain - Choosing the Right Tool for Your LLM Application\\n\\nThis outline provides a comprehensive structure for a blog post comparing LangGraph and LangChain, aiming to help readers understand their differences, use cases, and help them make an informed decision.\\n\\n**I. Introduction (Approx. 150-200 words)**\\n\\n*   **Hook:** Start with a relatable pain point or exciting possibility in LLM application development. (e.g., \"Building complex LLM applications can feel like juggling,\" or \"The LLM landscape is exploding, and so are the tools to harness its power.\")\\n*   **Introduce the Problem:** Briefly mention the increasing complexity of LLM applications beyond simple prompts.\\n*   **Introduce the Players:**\\n    *   **LangChain:** Briefly introduce it as a foundational, widely adopted framework for LLM application development.\\n    *   **LangGraph:** Introduce it as a newer, more specialized library built *on top of* LangChain, focusing on stateful, cyclical LLM applications.\\n*   **Thesis Statement/Blog Goal:** Clearly state what the reader will gain from this post. (e.g., \"This post will demystify the differences between LangGraph and LangChain, explore their core strengths, and guide you in selecting the optimal tool for your specific LLM project.\")\\n*   **Briefly Outline the Blog\\'s Structure:** Give a roadmap of what to expect.\\n\\n**II. Understanding the Foundation: What is LangChain? (Approx. 300-400 words)**\\n\\n*   **Core Concept:** Explain LangChain\\'s purpose – to simplify LLM application development by providing modular components and abstractions.\\n*   **Key Components/Features (with brief explanations):**\\n    *   **Models:** LLMs, Chat Models, Embeddings.\\n    *   **Prompts:** Prompt templates, management.\\n    *   **Indexes:** Document loading, splitting, vector stores, retrievers.\\n    *   **Chains:** Sequential execution of LLM calls and other components.\\n    *   **Agents:** LLMs making decisions about which tools to use.\\n    *   **Memory:** Persisting conversation history.\\n*   **Strengths of LangChain:**\\n    *   **Versatility:** Wide range of use cases, from simple Q&A to complex agents.\\n    *   **Large Community & Ecosystem:** Abundant resources, examples, and integrations.\\n    *   **Rapid Prototyping:** Easy to get started and build basic applications.\\n    *   **Abstraction:** Simplifies interaction with LLMs and external tools.\\n*   **When to Use LangChain:**\\n    *   Simple LLM integrations.\\n    *   Building chatbots with basic memory.\\n    *   Implementing RAG (Retrieval Augmented Generation) pipelines.\\n    *   Experimenting with different LLMs and prompts.\\n    *   When you need a broad set of tools for diverse tasks.\\n\\n**III. Diving Deeper: What is LangGraph? (Approx. 400-500 words)**\\n\\n*   **Core Concept:** Explain LangGraph\\'s specialization – building *stateful, cyclical applications* with LLMs. Emphasize the \"graph\" and \"state\" aspects.\\n*   **Key Concepts/Features:**\\n    *   **State:** How LangGraph manages and passes information between steps. Introduce the concept of a `StateGraph`.\\n    *   **Nodes:** The individual computational units (LLM calls, tool executions, custom logic).\\n    *   **Edges:** The connections between nodes, defining the flow of execution.\\n    *   **Conditional Edges:** The power of decision-making within the graph based on the current state.\\n    *   **Cycles:** The ability for the graph to loop back on itself, crucial for iterative processes.\\n    *   **Built on LangChain:** Highlight that LangGraph leverages LangChain\\'s components (models, tools, etc.) and extends them.\\n*   **Illustrative Use Cases for LangGraph:**\\n    *   **Multi-agent systems:** Agents collaborating and communicating.\\n    *   **Iterative refinement:** LLMs improving their own outputs over multiple steps.\\n    *   **Complex decision trees:** Navigating through intricate logic.\\n    *   **Planning and execution loops:** Breaking down tasks and executing them step-by-step.\\n    *   **Simulations and games:** Creating dynamic, stateful environments.\\n*   **Strengths of LangGraph:**\\n    *   **Handling Complexity:** Excells at managing intricate, multi-step LLM interactions.\\n    *   **State Management:** Robust mechanisms for tracking and updating application state.\\n    *   **Explicit Control Flow:** Clear definition of how execution progresses and branches.\\n    *   **Modularity and Reusability:** Nodes and edges can be designed for reuse.\\n    *   **Debugging and Visualization:** The graph structure aids in understanding and debugging complex flows.\\n*   **When to Use LangGraph:**\\n    *   When your LLM application requires memory and iterative processing.\\n    *   For building multi-agent frameworks.\\n    *   When you need to model complex workflows with decision points.\\n    *   For applications that involve planning, execution, and refinement.\\n\\n**IV. The Core Differences: LangChain vs. LangGraph Head-to-Head (Approx. 400-500 words)**\\n\\n*   **Conceptual Focus:**\\n    *   LangChain: Broad toolkit, linear or branching chains.\\n    *   LangGraph: Stateful graphs, cyclical execution, explicit state management.\\n*   **State Management:**\\n    *   LangChain: Memory modules, often more implicit or managed externally.\\n    *   LangGraph: Centralized, explicit state management within the graph structure.\\n*   **Control Flow:**\\n    *   LangChain: Primarily sequential or simple branching.\\n    *   LangGraph: Highly flexible, supports complex conditional logic and cycles.\\n*   **Complexity Handling:**\\n    *   LangChain: Can become unwieldy for highly complex, stateful applications.\\n    *   LangGraph: Designed specifically for managing such complexity.\\n*   **Learning Curve:**\\n    *   LangChain: Easier to start with for basic use cases.\\n    *   LangGraph: May have a slightly steeper initial learning curve due to its graph-centric paradigm, but unlocks more power.\\n*   **Relationship:** Emphasize that LangGraph is *not* a replacement for LangChain, but rather a powerful extension or specialized layer built *upon* it.\\n\\n**V. Choosing the Right Tool for Your Project (Approx. 200-300 words)**\\n\\n*   **Decision Tree/Questions to Ask Yourself:**\\n    *   Does my application need to remember context and iterate on its outputs? (LangGraph)\\n    *   Am I building a simple Q&A bot or a RAG system? (LangChain might suffice)\\n    *   Do I need to orchestrate multiple LLM agents interacting with each other? (LangGraph)\\n    *   Is my application\\'s logic primarily linear or does it involve complex branching and looping? (LangGraph for complexity)\\n    *   Am I comfortable with graph-based programming concepts? (LangGraph)\\n    *   What is my team\\'s existing familiarity with LangChain? (Leverage existing knowledge)\\n*   **Synergy:** How they can be used together (e.g., using LangChain components *within* LangGraph nodes).\\n\\n**VI. Practical Examples/Code Snippets (Optional but highly recommended - Approx. 300-400 words)**\\n\\n*   **Simple LangChain Example:** A basic LLMChain for text generation or a simple RAG retrieval.\\n*   **Simple LangGraph Example:** A basic graph demonstrating state passing and a conditional edge. (e.g., a simple agent that decides whether to search or respond based on user input).\\n*   **Highlight the differences in code structure and how state is handled.**\\n\\n**VII. Conclusion (Approx. 100-150 words)**\\n\\n*   **Recap Key Takeaways:** Briefly reiterate the core strengths and differences.\\n*   **Reiterate the \"When to Use\" scenarios.**\\n*   **Future Outlook:** Briefly touch upon the evolving LLM development landscape.\\n*   **Call to Action:** Encourage readers to experiment, explore the documentation, and share their experiences. (e.g., \"Start building your next LLM application with confidence,\" or \"What are your thoughts on LangGraph vs. LangChain? Share in the comments below!\")\\n\\n**VIII. Resources & Further Reading (Optional)**\\n\\n*   Links to LangChain documentation.\\n*   Links to LangGraph documentation.\\n*   Relevant tutorials or blog posts.\\n*   Community forums or Discord channels.\\n\\n---\\n\\n**Tone and Style Considerations:**\\n\\n*   **Informative and Educational:** Aim to explain complex concepts clearly.\\n*   **Practical and Actionable:** Provide guidance that readers can use.\\n*   **Engaging:** Use analogies and relatable examples.\\n*   **Objective:** Present a balanced view of both frameworks.\\n*   **Target Audience:** Developers, AI enthusiasts, and anyone interested in building LLM applications.\\n\\nThis detailed outline should provide a strong foundation for a comprehensive and valuable blog post on LangGraph vs. LangChain. Remember to adapt and refine it based on your specific insights and the desired length of your post.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--c863cdda-b551-4055-a404-0d0daad1d01c-0', usage_metadata={'input_tokens': 17, 'output_tokens': 2009, 'total_tokens': 2026, 'input_token_details': {'cache_read': 0}}), 'content': '# LangGraph vs. LangChain: Choosing the Right Tool for Your LLM Application\\n\\nBuilding sophisticated Large Language Model (LLM) applications can feel like orchestrating a complex symphony. You\\'re not just sending a single prompt and getting a response; you\\'re often dealing with multi-step processes, dynamic decision-making, and applications that need to remember and evolve over time. In this rapidly evolving LLM landscape, two powerful frameworks stand out: LangChain and LangGraph. While both aim to simplify LLM development, they cater to different needs and offer distinct approaches.\\n\\nThis post will demystify the differences between LangGraph and LangChain, explore their core strengths, and guide you in selecting the optimal tool for your specific LLM project. We\\'ll start by understanding the foundational role of LangChain, then dive into the specialized power of LangGraph, directly compare their capabilities, and finally, help you make an informed decision.\\n\\n## Understanding the Foundation: What is LangChain?\\n\\nAt its heart, LangChain is a comprehensive framework designed to simplify the development of applications powered by LLMs. It provides a modular and extensible set of tools and abstractions that allow developers to easily connect LLMs with other data sources and computational capabilities. Think of it as a versatile toolkit that abstracts away much of the boilerplate code required to interact with LLMs and external services.\\n\\nLangChain\\'s strength lies in its broad applicability and its rich ecosystem. It offers a wide array of components, each serving a specific purpose:\\n\\n*   **Models:** This includes interfaces for various LLMs (like GPT-4, Claude), chat models, and embedding models, allowing you to easily swap between different providers and models.\\n*   **Prompts:** LangChain simplifies prompt engineering with prompt templates, allowing for dynamic input and output formatting, and prompt management.\\n*   **Indexes:** For applications that need to access external knowledge, LangChain provides tools for document loading, splitting, vector storage (like Chroma, Pinecone), and efficient retrieval. This is the backbone of Retrieval Augmented Generation (RAG) systems.\\n*   **Chains:** This is a core concept where you link multiple components together. A simple chain might involve a prompt template, an LLM call, and an output parser. More complex chains can orchestrate sequences of operations.\\n*   **Agents:** Agents are a powerful feature where an LLM acts as a reasoning engine, deciding which tools (like search engines, APIs, or other chains) to use to accomplish a given task.\\n*   **Memory:** To build conversational applications, LangChain offers various memory modules to persist conversation history, allowing the LLM to maintain context across multiple turns.\\n\\n**Strengths of LangChain:**\\n\\n*   **Versatility:** LangChain is adept at handling a wide spectrum of LLM use cases, from straightforward question-answering to intricate agent-based systems.\\n*   **Large Community & Ecosystem:** With a massive and active community, you\\'ll find abundant resources, tutorials, examples, and integrations for almost any LLM-related task.\\n*   **Rapid Prototyping:** Its intuitive structure makes it incredibly easy to get started and build basic LLM applications quickly.\\n*   **Abstraction:** It significantly simplifies the process of interacting with LLMs and integrating them with external tools and data.\\n\\n**When to Use LangChain:**\\n\\n*   When you need to integrate LLMs into simple applications, like generating text or summarizing content.\\n*   For building chatbots with basic memory that can recall recent conversation history.\\n*   Implementing RAG pipelines to enable LLMs to answer questions based on your custom data.\\n*   Experimenting with different LLMs, prompts, and basic agent functionalities.\\n*   When you require a broad set of tools to tackle diverse LLM-related tasks without needing complex state management or iterative loops.\\n\\n## Diving Deeper: What is LangGraph?\\n\\nLangGraph is a newer, specialized library built *on top of* LangChain. Its primary focus is on enabling the development of **stateful, cyclical LLM applications**. While LangChain excels at building linear or branching sequences, LangGraph introduces the concept of a \"graph\" where nodes represent computational steps and edges define the flow of execution, crucially allowing for **cycles** and explicit **state management**.\\n\\nThe core idea behind LangGraph is to model LLM applications as directed graphs. This paradigm shift is essential for applications that require iterative processing, complex decision-making loops, or multi-agent collaboration.\\n\\n**Key Concepts in LangGraph:**\\n\\n*   **State:** LangGraph\\'s most significant contribution is its robust state management. An application\\'s state is explicitly defined and passed between different steps (nodes) of the graph. This state can be anything from simple variables to complex data structures. The `StateGraph` class is the central construct for defining this state.\\n*   **Nodes:** These are the individual computational units within the graph. A node can be an LLM call, a tool execution, a custom Python function, or any piece of logic that transforms the state.\\n*   **Edges:** Edges represent the connections between nodes, dictating the flow of execution. They define which node runs next based on the current state.\\n*   **Conditional Edges:** This is where LangGraph truly shines. Conditional edges allow the graph to make decisions based on the current state. For example, an agent might decide to search the web if its current knowledge is insufficient, or to respond directly if it has enough information.\\n*   **Cycles:** The ability for the graph to loop back on itself is fundamental to LangGraph. This is crucial for iterative processes where an LLM might refine its output over several steps, or for multi-agent systems where agents communicate and act in rounds.\\n*   **Built on LangChain:** It\\'s important to remember that LangGraph doesn\\'t reinvent the wheel. It leverages LangChain\\'s powerful components (models, tools, retrievers, etc.) and provides a framework for orchestrating them in a stateful, graph-like manner.\\n\\n**Illustrative Use Cases for LangGraph:**\\n\\n*   **Multi-agent systems:** Orchestrating multiple AI agents that communicate, collaborate, and make decisions in a cyclical fashion.\\n*   **Iterative refinement:** LLMs that continuously improve their own outputs, such as code generation or complex problem-solving, by looping through evaluation and modification steps.\\n*   **Complex decision trees:** Applications that navigate through intricate logic with multiple branching and looping possibilities.\\n*   **Planning and execution loops:** Breaking down a complex task into smaller sub-tasks, executing them, and then planning the next steps based on the results.\\n*   **Simulations and games:** Creating dynamic, stateful environments where LLM-driven characters or systems interact and evolve.\\n\\n**Strengths of LangGraph:**\\n\\n*   **Handling Complexity:** LangGraph is specifically designed to manage intricate, multi-step LLM interactions that involve state and iteration.\\n*   **State Management:** Its explicit and centralized state management makes it easier to track and update application data throughout complex workflows.\\n*   **Explicit Control Flow:** The graph structure provides clear visibility into how execution progresses, branches, and loops, aiding in understanding and debugging.\\n*   **Modularity and Reusability:** Nodes and edges can be designed as reusable components, promoting cleaner code and easier maintenance.\\n*   **Debugging and Visualization:** The inherent graph structure makes it easier to visualize and debug complex LLM application flows.\\n\\n**When to Use LangGraph:**\\n\\n*   When your LLM application requires memory and iterative processing to achieve its goals.\\n*   For building sophisticated multi-agent frameworks where agents need to interact and make decisions over multiple rounds.\\n*   When you need to model complex workflows with dynamic decision points and potential loops.\\n*   For applications that involve planning, execution, and iterative refinement of outputs.\\n*   If you are comfortable with graph-based programming concepts and want fine-grained control over your LLM application\\'s flow.\\n\\n## The Core Differences: LangChain vs. LangGraph Head-to-Head\\n\\nWhile LangGraph builds upon LangChain, their fundamental approaches and use cases diverge significantly.\\n\\n| Feature           | LangChain                                        | LangGraph                                            |\\n| :---------------- | :----------------------------------------------- | :--------------------------------------------------- |\\n| **Conceptual Focus** | Broad toolkit, linear or branching chains.       | Stateful graphs, cyclical execution, explicit state. |\\n| **State Management** | Memory modules, often more implicit or external. | Centralized, explicit state management within the graph. |\\n| **Control Flow**  | Primarily sequential or simple branching.        | Highly flexible, supports complex conditional logic and cycles. |\\n| **Complexity Handling** | Can become unwieldy for highly complex, stateful applications. | Designed specifically for managing such complexity. |\\n| **Learning Curve** | Easier to start with for basic use cases.        | May have a slightly steeper initial curve, but unlocks more power. |\\n| **Relationship**  | A foundational framework.                        | A specialized library built on top of LangChain.     |\\n\\n**Conceptual Focus:** LangChain is like a toolbox with many individual tools and some basic assembly instructions (chains). You can connect these tools in a sequence. LangGraph, on the other hand, is a blueprint for building intricate machinery. It defines how different components (nodes) interact and pass information (state) in a dynamic, potentially looping fashion.\\n\\n**State Management:** In LangChain, memory is often an add-on module. In LangGraph, state is a first-class citizen. The entire graph is designed around passing and updating this explicit state, making it much easier to reason about and manage complex application states.\\n\\n**Control Flow:** LangChain\\'s chains are largely linear, with some ability to branch. LangGraph\\'s graph structure, especially with conditional edges and cycles, allows for much more sophisticated and dynamic control flow. Think of it as the difference between a straight road and a maze with decision points.\\n\\n**Complexity Handling:** For simple LLM tasks, LangChain is more than sufficient. However, as your application\\'s logic becomes more intricate, with multiple agents interacting or iterative refinement processes, LangChain can start to feel cumbersome. LangGraph is purpose-built for these complex scenarios.\\n\\n**Learning Curve:** LangChain is generally easier to pick up for beginners due to its more straightforward linear chaining. LangGraph\\'s graph-centric paradigm might require a bit more upfront understanding, but mastering it unlocks the ability to build much more powerful and dynamic applications.\\n\\n**Relationship:** It\\'s crucial to understand that LangGraph is not a replacement for LangChain. Instead, it\\'s a powerful extension. You\\'ll still use LangChain\\'s core components (LLMs, prompts, tools) within your LangGraph nodes. LangGraph provides the orchestration layer for these components in a stateful, cyclical manner.\\n\\n## Choosing the Right Tool for Your Project\\n\\nDeciding between LangChain and LangGraph depends entirely on the nature of your LLM application. Ask yourself these questions:\\n\\n*   **Does my application need to remember context and iterate on its outputs over multiple steps?** If yes, LangGraph is likely your best bet.\\n*   **Am I building a simple Q&A bot, a document summarizer, or a basic RAG system?** LangChain might be perfectly sufficient and easier to implement.\\n*   **Do I need to orchestrate multiple LLM agents interacting with each other in a dynamic way?** LangGraph is ideal for multi-agent frameworks.\\n*   **Is my application\\'s logic primarily linear or does it involve complex branching, decision-making, and looping?** For complexity, LangGraph offers superior control.\\n*   **Am I comfortable with graph-based programming concepts and explicit state management?** If so, LangGraph will empower you.\\n*   **What is my team\\'s existing familiarity with LangChain?** Leveraging existing knowledge can accelerate development.\\n\\n**Synergy:** Remember, these tools are not mutually exclusive. You can effectively use LangChain components *within* LangGraph nodes. For example, a LangGraph node might use a LangChain RAG retriever to fetch documents, process them with a LangChain LLM, and then update the graph\\'s state.\\n\\n## Practical Examples\\n\\nLet\\'s illustrate with simplified examples:\\n\\n### Simple LangChain Example: Basic RAG Retrieval\\n\\n```python\\nfrom langchain_community.document_loaders import TextLoader\\nfrom langchain_text_splitters import CharacterTextSplitter\\nfrom langchain_community.vectorstores import Chroma\\nfrom langchain_community.embeddings import OpenAIEmbeddings\\nfrom langchain_core.runnables import RunnablePassthrough\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_openai import ChatOpenAI\\n\\n# Load and split documents\\nloader = TextLoader(\"my_document.txt\")\\ndocuments = loader.load()\\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\\ntexts = text_splitter.split_documents(documents)\\n\\n# Create embeddings and vector store\\nembeddings = OpenAIEmbeddings()\\nvectorstore = Chroma.from_documents(texts, embeddings)\\nretriever = vectorstore.as_retriever()\\n\\n# Define a simple RAG chain\\nprompt = ChatPromptTemplate.from_template(\\n    \"Answer the question based on the context:\\\\n\\\\n{context}\\\\n\\\\nQuestion: {question}\"\\n)\\nmodel = ChatOpenAI()\\n\\ndef format_docs(docs):\\n    return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\\n\\nrag_chain = (\\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\\n    | prompt\\n    | model\\n)\\n\\n# Example usage\\nquestion = \"What is the main topic of the document?\"\\nanswer = rag_chain.invoke(question)\\nprint(f\"Answer: {answer.content}\")\\n```\\n\\nThis LangChain example sets up a RAG pipeline in a linear fashion.\\n\\n### Simple LangGraph Example: Basic Agent with Decision\\n\\n```python\\nfrom typing import List, Dict, Annotated\\nfrom langchain_core.tools import tool\\nfrom langgraph.graph import StateGraph, END\\n\\n# Define the state for our graph\\nclass AgentState(TypedDict):\\n    input: str\\n    intermediate_steps: Annotated[List[tuple], operator.add] | None\\n\\n# Define a tool\\n@tool\\ndef search_tool(query: str) -> str:\\n    \"\"\"Searches the web for information.\"\"\"\\n    # In a real app, this would call a search API\\n    return f\"Results for {query}: Some relevant information found.\"\\n\\n# Define nodes\\ndef call_search_tool(state: AgentState):\\n    input_str = state[\\'input\\']\\n    if not input_str:\\n        return {} # No input, do nothing\\n    tool_result = search_tool.invoke(input_str)\\n    return {\"intermediate_steps\": [(search_tool.name, tool_result)]}\\n\\ndef decide_on_action(state: AgentState):\\n    # In a real app, an LLM would make this decision based on state\\n    # For simplicity, we\\'ll hardcode a decision\\n    if state[\\'intermediate_steps\\']:\\n        return \"search_complete\"\\n    else:\\n        return \"respond_directly\" # Not implemented in this simple example\\n\\ndef respond_directly(state: AgentState):\\n    # Logic to formulate a direct response\\n    return {\"output\": f\"Direct response based on input: {state[\\'input\\']}\"}\\n\\n# Build the graph\\nbuilder = StateGraph(AgentState)\\n\\n# Add nodes\\nbuilder.add_node(\"call_search_tool\", call_search_tool)\\nbuilder.add_node(\"respond_directly\", respond_directly) # Placeholder node\\n\\n# Add edges\\nbuilder.add_edge(\"call_search_tool\", \"decide_on_action\") # After search, decide next step\\nbuilder.add_conditional_edges(\\n    \"decide_on_action\",\\n    decide_on_action,\\n    {\\n        \"search_complete\": \"respond_directly\", # If search is done, proceed\\n        \"respond_directly\": \"respond_directly\", # If decided to respond directly\\n    }\\n)\\nbuilder.add_edge(\"respond_directly\", END) # End after responding\\n\\n# Set the entry point\\nbuilder.set_entry_point(\"call_search_tool\") # Start by attempting search\\n\\n# Compile the graph\\ngraph = builder.compile()\\n\\n# Example usage\\n# To trigger the \"decide_on_action\" node, we need to pass input\\n# and then the graph will decide the next step.\\n# For this simplified example, let\\'s assume we want to search.\\n# In a real scenario, the LLM would decide to search.\\nprint(graph.invoke({\"input\": \"weather in London\"}))\\n\\n# If we want to skip the search and go directly to a response (hypothetically)\\n# this would require a different graph setup or conditional logic.\\n# For demo purposes, the above invoke will go through the search and then the decision.\\n```\\n\\nThis LangGraph example shows a basic graph with a tool call and a conditional edge for decision-making. Notice how the `AgentState` explicitly carries information.\\n\\n## Conclusion\\n\\nLangChain and LangGraph are both invaluable tools in the LLM development arsenal, but they serve distinct purposes. LangChain provides a broad, flexible foundation for building a wide range of LLM applications, excelling in rapid prototyping and straightforward integrations. LangGraph, on the other hand, offers a specialized, powerful approach for tackling complex, stateful, and cyclical LLM applications, particularly those involving multi-agent systems or iterative refinement.\\n\\n**Recap:**\\n\\n*   **LangChain:** Ideal for simple to moderately complex LLM integrations, RAG, chatbots with basic memory, and general LLM experimentation.\\n*   **LangGraph:** Essential for complex workflows, multi-agent systems, applications requiring iterative processing, and fine-grained control over state and execution flow.\\n\\nThe LLM development landscape is continuously evolving, and understanding the strengths of tools like LangChain and LangGraph empowers you to build more sophisticated and effective AI applications.\\n\\n**Start building your next LLM application with confidence!** Experiment with both frameworks, explore their documentation, and choose the tool that best aligns with your project\\'s unique requirements.\\n\\nWhat are your thoughts on LangGraph vs. LangChain? Share your experiences and insights in the comments below!\\n\\n---\\n\\n## Resources & Further Reading\\n\\n*   **LangChain Documentation:** [https://python.langchain.com/](https://python.langchain.com/)\\n*   **LangGraph Documentation:** [https://langchain.com/langgraph](https://langchain.com/langgraph)\\n*   **LangChain Community Discord:** (Search for LangChain Discord on your preferred platform)'}\n"
     ]
    }
   ],
   "source": [
    "intial_state = {'title': 'LangGraph vs LangChain'}\n",
    "\n",
    "final_state = workflow.invoke(intial_state)\n",
    "\n",
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1894db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='## Blog Post Outline: LangGraph vs. LangChain - Choosing the Right Tool for Your LLM Application\\n\\nThis outline provides a comprehensive structure for a blog post comparing LangGraph and LangChain, aiming to help readers understand their differences, use cases, and help them make an informed decision.\\n\\n**I. Introduction (Approx. 150-200 words)**\\n\\n*   **Hook:** Start with a relatable pain point or exciting possibility in LLM application development. (e.g., \"Building complex LLM applications can feel like juggling,\" or \"The LLM landscape is exploding, and so are the tools to harness its power.\")\\n*   **Introduce the Problem:** Briefly mention the increasing complexity of LLM applications beyond simple prompts.\\n*   **Introduce the Players:**\\n    *   **LangChain:** Briefly introduce it as a foundational, widely adopted framework for LLM application development.\\n    *   **LangGraph:** Introduce it as a newer, more specialized library built *on top of* LangChain, focusing on stateful, cyclical LLM applications.\\n*   **Thesis Statement/Blog Goal:** Clearly state what the reader will gain from this post. (e.g., \"This post will demystify the differences between LangGraph and LangChain, explore their core strengths, and guide you in selecting the optimal tool for your specific LLM project.\")\\n*   **Briefly Outline the Blog\\'s Structure:** Give a roadmap of what to expect.\\n\\n**II. Understanding the Foundation: What is LangChain? (Approx. 300-400 words)**\\n\\n*   **Core Concept:** Explain LangChain\\'s purpose – to simplify LLM application development by providing modular components and abstractions.\\n*   **Key Components/Features (with brief explanations):**\\n    *   **Models:** LLMs, Chat Models, Embeddings.\\n    *   **Prompts:** Prompt templates, management.\\n    *   **Indexes:** Document loading, splitting, vector stores, retrievers.\\n    *   **Chains:** Sequential execution of LLM calls and other components.\\n    *   **Agents:** LLMs making decisions about which tools to use.\\n    *   **Memory:** Persisting conversation history.\\n*   **Strengths of LangChain:**\\n    *   **Versatility:** Wide range of use cases, from simple Q&A to complex agents.\\n    *   **Large Community & Ecosystem:** Abundant resources, examples, and integrations.\\n    *   **Rapid Prototyping:** Easy to get started and build basic applications.\\n    *   **Abstraction:** Simplifies interaction with LLMs and external tools.\\n*   **When to Use LangChain:**\\n    *   Simple LLM integrations.\\n    *   Building chatbots with basic memory.\\n    *   Implementing RAG (Retrieval Augmented Generation) pipelines.\\n    *   Experimenting with different LLMs and prompts.\\n    *   When you need a broad set of tools for diverse tasks.\\n\\n**III. Diving Deeper: What is LangGraph? (Approx. 400-500 words)**\\n\\n*   **Core Concept:** Explain LangGraph\\'s specialization – building *stateful, cyclical applications* with LLMs. Emphasize the \"graph\" and \"state\" aspects.\\n*   **Key Concepts/Features:**\\n    *   **State:** How LangGraph manages and passes information between steps. Introduce the concept of a `StateGraph`.\\n    *   **Nodes:** The individual computational units (LLM calls, tool executions, custom logic).\\n    *   **Edges:** The connections between nodes, defining the flow of execution.\\n    *   **Conditional Edges:** The power of decision-making within the graph based on the current state.\\n    *   **Cycles:** The ability for the graph to loop back on itself, crucial for iterative processes.\\n    *   **Built on LangChain:** Highlight that LangGraph leverages LangChain\\'s components (models, tools, etc.) and extends them.\\n*   **Illustrative Use Cases for LangGraph:**\\n    *   **Multi-agent systems:** Agents collaborating and communicating.\\n    *   **Iterative refinement:** LLMs improving their own outputs over multiple steps.\\n    *   **Complex decision trees:** Navigating through intricate logic.\\n    *   **Planning and execution loops:** Breaking down tasks and executing them step-by-step.\\n    *   **Simulations and games:** Creating dynamic, stateful environments.\\n*   **Strengths of LangGraph:**\\n    *   **Handling Complexity:** Excells at managing intricate, multi-step LLM interactions.\\n    *   **State Management:** Robust mechanisms for tracking and updating application state.\\n    *   **Explicit Control Flow:** Clear definition of how execution progresses and branches.\\n    *   **Modularity and Reusability:** Nodes and edges can be designed for reuse.\\n    *   **Debugging and Visualization:** The graph structure aids in understanding and debugging complex flows.\\n*   **When to Use LangGraph:**\\n    *   When your LLM application requires memory and iterative processing.\\n    *   For building multi-agent frameworks.\\n    *   When you need to model complex workflows with decision points.\\n    *   For applications that involve planning, execution, and refinement.\\n\\n**IV. The Core Differences: LangChain vs. LangGraph Head-to-Head (Approx. 400-500 words)**\\n\\n*   **Conceptual Focus:**\\n    *   LangChain: Broad toolkit, linear or branching chains.\\n    *   LangGraph: Stateful graphs, cyclical execution, explicit state management.\\n*   **State Management:**\\n    *   LangChain: Memory modules, often more implicit or managed externally.\\n    *   LangGraph: Centralized, explicit state management within the graph structure.\\n*   **Control Flow:**\\n    *   LangChain: Primarily sequential or simple branching.\\n    *   LangGraph: Highly flexible, supports complex conditional logic and cycles.\\n*   **Complexity Handling:**\\n    *   LangChain: Can become unwieldy for highly complex, stateful applications.\\n    *   LangGraph: Designed specifically for managing such complexity.\\n*   **Learning Curve:**\\n    *   LangChain: Easier to start with for basic use cases.\\n    *   LangGraph: May have a slightly steeper initial learning curve due to its graph-centric paradigm, but unlocks more power.\\n*   **Relationship:** Emphasize that LangGraph is *not* a replacement for LangChain, but rather a powerful extension or specialized layer built *upon* it.\\n\\n**V. Choosing the Right Tool for Your Project (Approx. 200-300 words)**\\n\\n*   **Decision Tree/Questions to Ask Yourself:**\\n    *   Does my application need to remember context and iterate on its outputs? (LangGraph)\\n    *   Am I building a simple Q&A bot or a RAG system? (LangChain might suffice)\\n    *   Do I need to orchestrate multiple LLM agents interacting with each other? (LangGraph)\\n    *   Is my application\\'s logic primarily linear or does it involve complex branching and looping? (LangGraph for complexity)\\n    *   Am I comfortable with graph-based programming concepts? (LangGraph)\\n    *   What is my team\\'s existing familiarity with LangChain? (Leverage existing knowledge)\\n*   **Synergy:** How they can be used together (e.g., using LangChain components *within* LangGraph nodes).\\n\\n**VI. Practical Examples/Code Snippets (Optional but highly recommended - Approx. 300-400 words)**\\n\\n*   **Simple LangChain Example:** A basic LLMChain for text generation or a simple RAG retrieval.\\n*   **Simple LangGraph Example:** A basic graph demonstrating state passing and a conditional edge. (e.g., a simple agent that decides whether to search or respond based on user input).\\n*   **Highlight the differences in code structure and how state is handled.**\\n\\n**VII. Conclusion (Approx. 100-150 words)**\\n\\n*   **Recap Key Takeaways:** Briefly reiterate the core strengths and differences.\\n*   **Reiterate the \"When to Use\" scenarios.**\\n*   **Future Outlook:** Briefly touch upon the evolving LLM development landscape.\\n*   **Call to Action:** Encourage readers to experiment, explore the documentation, and share their experiences. (e.g., \"Start building your next LLM application with confidence,\" or \"What are your thoughts on LangGraph vs. LangChain? Share in the comments below!\")\\n\\n**VIII. Resources & Further Reading (Optional)**\\n\\n*   Links to LangChain documentation.\\n*   Links to LangGraph documentation.\\n*   Relevant tutorials or blog posts.\\n*   Community forums or Discord channels.\\n\\n---\\n\\n**Tone and Style Considerations:**\\n\\n*   **Informative and Educational:** Aim to explain complex concepts clearly.\\n*   **Practical and Actionable:** Provide guidance that readers can use.\\n*   **Engaging:** Use analogies and relatable examples.\\n*   **Objective:** Present a balanced view of both frameworks.\\n*   **Target Audience:** Developers, AI enthusiasts, and anyone interested in building LLM applications.\\n\\nThis detailed outline should provide a strong foundation for a comprehensive and valuable blog post on LangGraph vs. LangChain. Remember to adapt and refine it based on your specific insights and the desired length of your post.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'} id='lc_run--c863cdda-b551-4055-a404-0d0daad1d01c-0' usage_metadata={'input_tokens': 17, 'output_tokens': 2009, 'total_tokens': 2026, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(final_state['outline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c255864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LangGraph vs. LangChain: Choosing the Right Tool for Your LLM Application\n",
      "\n",
      "Building sophisticated Large Language Model (LLM) applications can feel like orchestrating a complex symphony. You're not just sending a single prompt and getting a response; you're often dealing with multi-step processes, dynamic decision-making, and applications that need to remember and evolve over time. In this rapidly evolving LLM landscape, two powerful frameworks stand out: LangChain and LangGraph. While both aim to simplify LLM development, they cater to different needs and offer distinct approaches.\n",
      "\n",
      "This post will demystify the differences between LangGraph and LangChain, explore their core strengths, and guide you in selecting the optimal tool for your specific LLM project. We'll start by understanding the foundational role of LangChain, then dive into the specialized power of LangGraph, directly compare their capabilities, and finally, help you make an informed decision.\n",
      "\n",
      "## Understanding the Foundation: What is LangChain?\n",
      "\n",
      "At its heart, LangChain is a comprehensive framework designed to simplify the development of applications powered by LLMs. It provides a modular and extensible set of tools and abstractions that allow developers to easily connect LLMs with other data sources and computational capabilities. Think of it as a versatile toolkit that abstracts away much of the boilerplate code required to interact with LLMs and external services.\n",
      "\n",
      "LangChain's strength lies in its broad applicability and its rich ecosystem. It offers a wide array of components, each serving a specific purpose:\n",
      "\n",
      "*   **Models:** This includes interfaces for various LLMs (like GPT-4, Claude), chat models, and embedding models, allowing you to easily swap between different providers and models.\n",
      "*   **Prompts:** LangChain simplifies prompt engineering with prompt templates, allowing for dynamic input and output formatting, and prompt management.\n",
      "*   **Indexes:** For applications that need to access external knowledge, LangChain provides tools for document loading, splitting, vector storage (like Chroma, Pinecone), and efficient retrieval. This is the backbone of Retrieval Augmented Generation (RAG) systems.\n",
      "*   **Chains:** This is a core concept where you link multiple components together. A simple chain might involve a prompt template, an LLM call, and an output parser. More complex chains can orchestrate sequences of operations.\n",
      "*   **Agents:** Agents are a powerful feature where an LLM acts as a reasoning engine, deciding which tools (like search engines, APIs, or other chains) to use to accomplish a given task.\n",
      "*   **Memory:** To build conversational applications, LangChain offers various memory modules to persist conversation history, allowing the LLM to maintain context across multiple turns.\n",
      "\n",
      "**Strengths of LangChain:**\n",
      "\n",
      "*   **Versatility:** LangChain is adept at handling a wide spectrum of LLM use cases, from straightforward question-answering to intricate agent-based systems.\n",
      "*   **Large Community & Ecosystem:** With a massive and active community, you'll find abundant resources, tutorials, examples, and integrations for almost any LLM-related task.\n",
      "*   **Rapid Prototyping:** Its intuitive structure makes it incredibly easy to get started and build basic LLM applications quickly.\n",
      "*   **Abstraction:** It significantly simplifies the process of interacting with LLMs and integrating them with external tools and data.\n",
      "\n",
      "**When to Use LangChain:**\n",
      "\n",
      "*   When you need to integrate LLMs into simple applications, like generating text or summarizing content.\n",
      "*   For building chatbots with basic memory that can recall recent conversation history.\n",
      "*   Implementing RAG pipelines to enable LLMs to answer questions based on your custom data.\n",
      "*   Experimenting with different LLMs, prompts, and basic agent functionalities.\n",
      "*   When you require a broad set of tools to tackle diverse LLM-related tasks without needing complex state management or iterative loops.\n",
      "\n",
      "## Diving Deeper: What is LangGraph?\n",
      "\n",
      "LangGraph is a newer, specialized library built *on top of* LangChain. Its primary focus is on enabling the development of **stateful, cyclical LLM applications**. While LangChain excels at building linear or branching sequences, LangGraph introduces the concept of a \"graph\" where nodes represent computational steps and edges define the flow of execution, crucially allowing for **cycles** and explicit **state management**.\n",
      "\n",
      "The core idea behind LangGraph is to model LLM applications as directed graphs. This paradigm shift is essential for applications that require iterative processing, complex decision-making loops, or multi-agent collaboration.\n",
      "\n",
      "**Key Concepts in LangGraph:**\n",
      "\n",
      "*   **State:** LangGraph's most significant contribution is its robust state management. An application's state is explicitly defined and passed between different steps (nodes) of the graph. This state can be anything from simple variables to complex data structures. The `StateGraph` class is the central construct for defining this state.\n",
      "*   **Nodes:** These are the individual computational units within the graph. A node can be an LLM call, a tool execution, a custom Python function, or any piece of logic that transforms the state.\n",
      "*   **Edges:** Edges represent the connections between nodes, dictating the flow of execution. They define which node runs next based on the current state.\n",
      "*   **Conditional Edges:** This is where LangGraph truly shines. Conditional edges allow the graph to make decisions based on the current state. For example, an agent might decide to search the web if its current knowledge is insufficient, or to respond directly if it has enough information.\n",
      "*   **Cycles:** The ability for the graph to loop back on itself is fundamental to LangGraph. This is crucial for iterative processes where an LLM might refine its output over several steps, or for multi-agent systems where agents communicate and act in rounds.\n",
      "*   **Built on LangChain:** It's important to remember that LangGraph doesn't reinvent the wheel. It leverages LangChain's powerful components (models, tools, retrievers, etc.) and provides a framework for orchestrating them in a stateful, graph-like manner.\n",
      "\n",
      "**Illustrative Use Cases for LangGraph:**\n",
      "\n",
      "*   **Multi-agent systems:** Orchestrating multiple AI agents that communicate, collaborate, and make decisions in a cyclical fashion.\n",
      "*   **Iterative refinement:** LLMs that continuously improve their own outputs, such as code generation or complex problem-solving, by looping through evaluation and modification steps.\n",
      "*   **Complex decision trees:** Applications that navigate through intricate logic with multiple branching and looping possibilities.\n",
      "*   **Planning and execution loops:** Breaking down a complex task into smaller sub-tasks, executing them, and then planning the next steps based on the results.\n",
      "*   **Simulations and games:** Creating dynamic, stateful environments where LLM-driven characters or systems interact and evolve.\n",
      "\n",
      "**Strengths of LangGraph:**\n",
      "\n",
      "*   **Handling Complexity:** LangGraph is specifically designed to manage intricate, multi-step LLM interactions that involve state and iteration.\n",
      "*   **State Management:** Its explicit and centralized state management makes it easier to track and update application data throughout complex workflows.\n",
      "*   **Explicit Control Flow:** The graph structure provides clear visibility into how execution progresses, branches, and loops, aiding in understanding and debugging.\n",
      "*   **Modularity and Reusability:** Nodes and edges can be designed as reusable components, promoting cleaner code and easier maintenance.\n",
      "*   **Debugging and Visualization:** The inherent graph structure makes it easier to visualize and debug complex LLM application flows.\n",
      "\n",
      "**When to Use LangGraph:**\n",
      "\n",
      "*   When your LLM application requires memory and iterative processing to achieve its goals.\n",
      "*   For building sophisticated multi-agent frameworks where agents need to interact and make decisions over multiple rounds.\n",
      "*   When you need to model complex workflows with dynamic decision points and potential loops.\n",
      "*   For applications that involve planning, execution, and iterative refinement of outputs.\n",
      "*   If you are comfortable with graph-based programming concepts and want fine-grained control over your LLM application's flow.\n",
      "\n",
      "## The Core Differences: LangChain vs. LangGraph Head-to-Head\n",
      "\n",
      "While LangGraph builds upon LangChain, their fundamental approaches and use cases diverge significantly.\n",
      "\n",
      "| Feature           | LangChain                                        | LangGraph                                            |\n",
      "| :---------------- | :----------------------------------------------- | :--------------------------------------------------- |\n",
      "| **Conceptual Focus** | Broad toolkit, linear or branching chains.       | Stateful graphs, cyclical execution, explicit state. |\n",
      "| **State Management** | Memory modules, often more implicit or external. | Centralized, explicit state management within the graph. |\n",
      "| **Control Flow**  | Primarily sequential or simple branching.        | Highly flexible, supports complex conditional logic and cycles. |\n",
      "| **Complexity Handling** | Can become unwieldy for highly complex, stateful applications. | Designed specifically for managing such complexity. |\n",
      "| **Learning Curve** | Easier to start with for basic use cases.        | May have a slightly steeper initial curve, but unlocks more power. |\n",
      "| **Relationship**  | A foundational framework.                        | A specialized library built on top of LangChain.     |\n",
      "\n",
      "**Conceptual Focus:** LangChain is like a toolbox with many individual tools and some basic assembly instructions (chains). You can connect these tools in a sequence. LangGraph, on the other hand, is a blueprint for building intricate machinery. It defines how different components (nodes) interact and pass information (state) in a dynamic, potentially looping fashion.\n",
      "\n",
      "**State Management:** In LangChain, memory is often an add-on module. In LangGraph, state is a first-class citizen. The entire graph is designed around passing and updating this explicit state, making it much easier to reason about and manage complex application states.\n",
      "\n",
      "**Control Flow:** LangChain's chains are largely linear, with some ability to branch. LangGraph's graph structure, especially with conditional edges and cycles, allows for much more sophisticated and dynamic control flow. Think of it as the difference between a straight road and a maze with decision points.\n",
      "\n",
      "**Complexity Handling:** For simple LLM tasks, LangChain is more than sufficient. However, as your application's logic becomes more intricate, with multiple agents interacting or iterative refinement processes, LangChain can start to feel cumbersome. LangGraph is purpose-built for these complex scenarios.\n",
      "\n",
      "**Learning Curve:** LangChain is generally easier to pick up for beginners due to its more straightforward linear chaining. LangGraph's graph-centric paradigm might require a bit more upfront understanding, but mastering it unlocks the ability to build much more powerful and dynamic applications.\n",
      "\n",
      "**Relationship:** It's crucial to understand that LangGraph is not a replacement for LangChain. Instead, it's a powerful extension. You'll still use LangChain's core components (LLMs, prompts, tools) within your LangGraph nodes. LangGraph provides the orchestration layer for these components in a stateful, cyclical manner.\n",
      "\n",
      "## Choosing the Right Tool for Your Project\n",
      "\n",
      "Deciding between LangChain and LangGraph depends entirely on the nature of your LLM application. Ask yourself these questions:\n",
      "\n",
      "*   **Does my application need to remember context and iterate on its outputs over multiple steps?** If yes, LangGraph is likely your best bet.\n",
      "*   **Am I building a simple Q&A bot, a document summarizer, or a basic RAG system?** LangChain might be perfectly sufficient and easier to implement.\n",
      "*   **Do I need to orchestrate multiple LLM agents interacting with each other in a dynamic way?** LangGraph is ideal for multi-agent frameworks.\n",
      "*   **Is my application's logic primarily linear or does it involve complex branching, decision-making, and looping?** For complexity, LangGraph offers superior control.\n",
      "*   **Am I comfortable with graph-based programming concepts and explicit state management?** If so, LangGraph will empower you.\n",
      "*   **What is my team's existing familiarity with LangChain?** Leveraging existing knowledge can accelerate development.\n",
      "\n",
      "**Synergy:** Remember, these tools are not mutually exclusive. You can effectively use LangChain components *within* LangGraph nodes. For example, a LangGraph node might use a LangChain RAG retriever to fetch documents, process them with a LangChain LLM, and then update the graph's state.\n",
      "\n",
      "## Practical Examples\n",
      "\n",
      "Let's illustrate with simplified examples:\n",
      "\n",
      "### Simple LangChain Example: Basic RAG Retrieval\n",
      "\n",
      "```python\n",
      "from langchain_community.document_loaders import TextLoader\n",
      "from langchain_text_splitters import CharacterTextSplitter\n",
      "from langchain_community.vectorstores import Chroma\n",
      "from langchain_community.embeddings import OpenAIEmbeddings\n",
      "from langchain_core.runnables import RunnablePassthrough\n",
      "from langchain_core.prompts import ChatPromptTemplate\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "# Load and split documents\n",
      "loader = TextLoader(\"my_document.txt\")\n",
      "documents = loader.load()\n",
      "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
      "texts = text_splitter.split_documents(documents)\n",
      "\n",
      "# Create embeddings and vector store\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vectorstore = Chroma.from_documents(texts, embeddings)\n",
      "retriever = vectorstore.as_retriever()\n",
      "\n",
      "# Define a simple RAG chain\n",
      "prompt = ChatPromptTemplate.from_template(\n",
      "    \"Answer the question based on the context:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
      ")\n",
      "model = ChatOpenAI()\n",
      "\n",
      "def format_docs(docs):\n",
      "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
      "\n",
      "rag_chain = (\n",
      "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
      "    | prompt\n",
      "    | model\n",
      ")\n",
      "\n",
      "# Example usage\n",
      "question = \"What is the main topic of the document?\"\n",
      "answer = rag_chain.invoke(question)\n",
      "print(f\"Answer: {answer.content}\")\n",
      "```\n",
      "\n",
      "This LangChain example sets up a RAG pipeline in a linear fashion.\n",
      "\n",
      "### Simple LangGraph Example: Basic Agent with Decision\n",
      "\n",
      "```python\n",
      "from typing import List, Dict, Annotated\n",
      "from langchain_core.tools import tool\n",
      "from langgraph.graph import StateGraph, END\n",
      "\n",
      "# Define the state for our graph\n",
      "class AgentState(TypedDict):\n",
      "    input: str\n",
      "    intermediate_steps: Annotated[List[tuple], operator.add] | None\n",
      "\n",
      "# Define a tool\n",
      "@tool\n",
      "def search_tool(query: str) -> str:\n",
      "    \"\"\"Searches the web for information.\"\"\"\n",
      "    # In a real app, this would call a search API\n",
      "    return f\"Results for {query}: Some relevant information found.\"\n",
      "\n",
      "# Define nodes\n",
      "def call_search_tool(state: AgentState):\n",
      "    input_str = state['input']\n",
      "    if not input_str:\n",
      "        return {} # No input, do nothing\n",
      "    tool_result = search_tool.invoke(input_str)\n",
      "    return {\"intermediate_steps\": [(search_tool.name, tool_result)]}\n",
      "\n",
      "def decide_on_action(state: AgentState):\n",
      "    # In a real app, an LLM would make this decision based on state\n",
      "    # For simplicity, we'll hardcode a decision\n",
      "    if state['intermediate_steps']:\n",
      "        return \"search_complete\"\n",
      "    else:\n",
      "        return \"respond_directly\" # Not implemented in this simple example\n",
      "\n",
      "def respond_directly(state: AgentState):\n",
      "    # Logic to formulate a direct response\n",
      "    return {\"output\": f\"Direct response based on input: {state['input']}\"}\n",
      "\n",
      "# Build the graph\n",
      "builder = StateGraph(AgentState)\n",
      "\n",
      "# Add nodes\n",
      "builder.add_node(\"call_search_tool\", call_search_tool)\n",
      "builder.add_node(\"respond_directly\", respond_directly) # Placeholder node\n",
      "\n",
      "# Add edges\n",
      "builder.add_edge(\"call_search_tool\", \"decide_on_action\") # After search, decide next step\n",
      "builder.add_conditional_edges(\n",
      "    \"decide_on_action\",\n",
      "    decide_on_action,\n",
      "    {\n",
      "        \"search_complete\": \"respond_directly\", # If search is done, proceed\n",
      "        \"respond_directly\": \"respond_directly\", # If decided to respond directly\n",
      "    }\n",
      ")\n",
      "builder.add_edge(\"respond_directly\", END) # End after responding\n",
      "\n",
      "# Set the entry point\n",
      "builder.set_entry_point(\"call_search_tool\") # Start by attempting search\n",
      "\n",
      "# Compile the graph\n",
      "graph = builder.compile()\n",
      "\n",
      "# Example usage\n",
      "# To trigger the \"decide_on_action\" node, we need to pass input\n",
      "# and then the graph will decide the next step.\n",
      "# For this simplified example, let's assume we want to search.\n",
      "# In a real scenario, the LLM would decide to search.\n",
      "print(graph.invoke({\"input\": \"weather in London\"}))\n",
      "\n",
      "# If we want to skip the search and go directly to a response (hypothetically)\n",
      "# this would require a different graph setup or conditional logic.\n",
      "# For demo purposes, the above invoke will go through the search and then the decision.\n",
      "```\n",
      "\n",
      "This LangGraph example shows a basic graph with a tool call and a conditional edge for decision-making. Notice how the `AgentState` explicitly carries information.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "LangChain and LangGraph are both invaluable tools in the LLM development arsenal, but they serve distinct purposes. LangChain provides a broad, flexible foundation for building a wide range of LLM applications, excelling in rapid prototyping and straightforward integrations. LangGraph, on the other hand, offers a specialized, powerful approach for tackling complex, stateful, and cyclical LLM applications, particularly those involving multi-agent systems or iterative refinement.\n",
      "\n",
      "**Recap:**\n",
      "\n",
      "*   **LangChain:** Ideal for simple to moderately complex LLM integrations, RAG, chatbots with basic memory, and general LLM experimentation.\n",
      "*   **LangGraph:** Essential for complex workflows, multi-agent systems, applications requiring iterative processing, and fine-grained control over state and execution flow.\n",
      "\n",
      "The LLM development landscape is continuously evolving, and understanding the strengths of tools like LangChain and LangGraph empowers you to build more sophisticated and effective AI applications.\n",
      "\n",
      "**Start building your next LLM application with confidence!** Experiment with both frameworks, explore their documentation, and choose the tool that best aligns with your project's unique requirements.\n",
      "\n",
      "What are your thoughts on LangGraph vs. LangChain? Share your experiences and insights in the comments below!\n",
      "\n",
      "---\n",
      "\n",
      "## Resources & Further Reading\n",
      "\n",
      "*   **LangChain Documentation:** [https://python.langchain.com/](https://python.langchain.com/)\n",
      "*   **LangGraph Documentation:** [https://langchain.com/langgraph](https://langchain.com/langgraph)\n",
      "*   **LangChain Community Discord:** (Search for LangChain Discord on your preferred platform)\n"
     ]
    }
   ],
   "source": [
    "print(final_state['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1efde6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langGr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
