Very difficult to debug the multiple stages to debug the whole LLM workflow in the LangGraph.
This is where LangSmith comes into play 

Observability: ability to understand system's internal state by examining the outputs like logs, metrics and traces
    - allows to diagnose issues, understand performance and improve reliability by analyzing data generated by the system.

LangSmith = a unified Observability and evaluation platform where teams can debug, test and monitor AI app performance

What does LangSmith traces?
    - input and outputs
    - all intermediate steps
    - latency
    - token usage
    - cost
    - error
    - tags
    - metadata
    - feedback
